{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM5MKWFokbreugPUNrP/n+h",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/youzhanghe123/Face-swapping-based-on-delaunay-triangulation/blob/main/face_swap_picture_video.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import dlib\n",
        "from google.colab.patches import cv2_imshow"
      ],
      "metadata": {
        "id": "TGpB72fNMkP1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "face swap algorithm"
      ],
      "metadata": {
        "id": "wcbBgbb_Q6Tx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def faceswap (sourceimg, targetimg): #we have source image and target image\n",
        "\n",
        "  def extract_index_nparray(nparray):\n",
        "    index = None\n",
        "    for num in nparray[0]:\n",
        "        index = num\n",
        "        break\n",
        "    return index\n",
        "\n",
        "\n",
        "  img=sourceimg\n",
        "  img_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "  mask = np.zeros_like(img_gray)\n",
        "\n",
        "  img2=targetimg\n",
        "  img2_gray = cv2.cvtColor(img2, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "\n",
        "  detector = dlib.get_frontal_face_detector()\n",
        "  predictor = dlib.shape_predictor(\"shape_predictor_68_face_landmarks.dat\")\n",
        "  height, width, channels = img2.shape\n",
        "  img2_new_face = np.zeros((height, width, channels), np.uint8)\n",
        "\n",
        "  # Face 1\n",
        "  faces = detector(img_gray)\n",
        "  for face in faces:\n",
        "      landmarks = predictor(img_gray, face)\n",
        "      landmarks_points = []\n",
        "      for n in range(0, 68):\n",
        "          x = landmarks.part(n).x\n",
        "          y = landmarks.part(n).y\n",
        "          landmarks_points.append((x, y))\n",
        "\n",
        "\n",
        "\n",
        "      points = np.array(landmarks_points, np.int32)\n",
        "      convexhull = cv2.convexHull(points)\n",
        "      # cv2.polylines(img, [convexhull], True, (255, 0, 0), 3)\n",
        "      cv2.fillConvexPoly(mask, convexhull, 255)\n",
        "\n",
        "      face_image_1 = cv2.bitwise_and(img, img, mask=mask)\n",
        "\n",
        "      # Delaunay triangulation\n",
        "      rect = cv2.boundingRect(convexhull)\n",
        "      subdiv = cv2.Subdiv2D(rect)\n",
        "      subdiv.insert(landmarks_points)\n",
        "      triangles = subdiv.getTriangleList()\n",
        "      triangles = np.array(triangles, dtype=np.int32)\n",
        "\n",
        "      indexes_triangles = []\n",
        "      for t in triangles:\n",
        "          pt1 = (t[0], t[1])\n",
        "          pt2 = (t[2], t[3])\n",
        "          pt3 = (t[4], t[5])\n",
        "\n",
        "\n",
        "          index_pt1 = np.where((points == pt1).all(axis=1))\n",
        "          index_pt1 = extract_index_nparray(index_pt1)\n",
        "\n",
        "          index_pt2 = np.where((points == pt2).all(axis=1))\n",
        "          index_pt2 = extract_index_nparray(index_pt2)\n",
        "\n",
        "          index_pt3 = np.where((points == pt3).all(axis=1))\n",
        "          index_pt3 = extract_index_nparray(index_pt3)\n",
        "\n",
        "          if index_pt1 is not None and index_pt2 is not None and index_pt3 is not None:\n",
        "              triangle = [index_pt1, index_pt2, index_pt3]\n",
        "              indexes_triangles.append(triangle)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  # Face 2\n",
        "  lines_space_mask = np.zeros_like(img_gray)\n",
        "  lines_space_new_face = np.zeros_like(img2)\n",
        "\n",
        "  faces2 = detector(img2_gray)\n",
        "  landmarks_points2 = [] #since we only have one face\n",
        "  for face in faces2:\n",
        "      landmarks = predictor(img2_gray, face)\n",
        "      #landmarks_points2 = []\n",
        "      for n in range(0, 68):\n",
        "          x = landmarks.part(n).x\n",
        "          y = landmarks.part(n).y\n",
        "          landmarks_points2.append((x, y))\n",
        "\n",
        "\n",
        "      points2 = np.array(landmarks_points2, np.int32)\n",
        "      convexhull2 = cv2.convexHull(points2)\n",
        "\n",
        "\n",
        "\n",
        "  if len(landmarks_points2)==0:\n",
        "    return img2\n",
        "\n",
        "  else:\n",
        "\n",
        "    # Triangulation of both faces\n",
        "    for triangle_index in indexes_triangles:\n",
        "        # Triangulation of the first face\n",
        "        tr1_pt1 = landmarks_points[triangle_index[0]]\n",
        "        tr1_pt2 = landmarks_points[triangle_index[1]]\n",
        "        tr1_pt3 = landmarks_points[triangle_index[2]]\n",
        "        triangle1 = np.array([tr1_pt1, tr1_pt2, tr1_pt3], np.int32)\n",
        "\n",
        "\n",
        "        rect1 = cv2.boundingRect(triangle1)\n",
        "        (x, y, w, h) = rect1\n",
        "        cropped_triangle = img[y: y + h, x: x + w]\n",
        "        cropped_tr1_mask = np.zeros((h, w), np.uint8)\n",
        "\n",
        "\n",
        "        points = np.array([[tr1_pt1[0] - x, tr1_pt1[1] - y],\n",
        "                          [tr1_pt2[0] - x, tr1_pt2[1] - y],\n",
        "                          [tr1_pt3[0] - x, tr1_pt3[1] - y]], np.int32)\n",
        "\n",
        "        cv2.fillConvexPoly(cropped_tr1_mask, points, 255)\n",
        "\n",
        "        # Lines space\n",
        "        cv2.line(lines_space_mask, tr1_pt1, tr1_pt2, 255)\n",
        "        cv2.line(lines_space_mask, tr1_pt2, tr1_pt3, 255)\n",
        "        cv2.line(lines_space_mask, tr1_pt1, tr1_pt3, 255)\n",
        "        lines_space = cv2.bitwise_and(img, img, mask=lines_space_mask)\n",
        "\n",
        "        # Triangulation of second face\n",
        "        tr2_pt1 = landmarks_points2[triangle_index[0]]\n",
        "        tr2_pt2 = landmarks_points2[triangle_index[1]]\n",
        "        tr2_pt3 = landmarks_points2[triangle_index[2]]\n",
        "        triangle2 = np.array([tr2_pt1, tr2_pt2, tr2_pt3], np.int32)\n",
        "\n",
        "\n",
        "        rect2 = cv2.boundingRect(triangle2)\n",
        "        (x, y, w, h) = rect2\n",
        "\n",
        "        cropped_tr2_mask = np.zeros((h, w), np.uint8)\n",
        "\n",
        "        points2 = np.array([[tr2_pt1[0] - x, tr2_pt1[1] - y],\n",
        "                            [tr2_pt2[0] - x, tr2_pt2[1] - y],\n",
        "                            [tr2_pt3[0] - x, tr2_pt3[1] - y]], np.int32)\n",
        "\n",
        "        cv2.fillConvexPoly(cropped_tr2_mask, points2, 255)\n",
        "\n",
        "\n",
        "\n",
        "        # Warp triangles\n",
        "        points = np.float32(points)\n",
        "        points2 = np.float32(points2)\n",
        "        M = cv2.getAffineTransform(points, points2)\n",
        "        warped_triangle = cv2.warpAffine(cropped_triangle, M, (w, h))\n",
        "        warped_triangle = cv2.bitwise_and(warped_triangle, warped_triangle, mask=cropped_tr2_mask)\n",
        "\n",
        "\n",
        "        # Reconstructing destination face\n",
        "        img2_new_face_rect_area = img2_new_face[y: y + h, x: x + w]\n",
        "        img2_new_face_rect_area_gray = cv2.cvtColor(img2_new_face_rect_area, cv2.COLOR_BGR2GRAY)\n",
        "        _, mask_triangles_designed = cv2.threshold(img2_new_face_rect_area_gray, 1, 255, cv2.THRESH_BINARY_INV)\n",
        "        warped_triangle = cv2.bitwise_and(warped_triangle, warped_triangle, mask=mask_triangles_designed)\n",
        "\n",
        "        img2_new_face_rect_area = cv2.add(img2_new_face_rect_area, warped_triangle)\n",
        "        img2_new_face[y: y + h, x: x + w] = img2_new_face_rect_area\n",
        "\n",
        "    # Face swapped (putting 1st face into 2nd face)\n",
        "    img2_face_mask = np.zeros_like(img2_gray)\n",
        "    img2_head_mask = cv2.fillConvexPoly(img2_face_mask, convexhull2, 255)\n",
        "    img2_face_mask = cv2.bitwise_not(img2_head_mask)\n",
        "\n",
        "\n",
        "    img2_head_noface = cv2.bitwise_and(img2, img2, mask=img2_face_mask)# make the region where we need to add the new faces on as black\n",
        "    result = cv2.add(img2_head_noface, img2_new_face)\n",
        "\n",
        "    (x, y, w, h) = cv2.boundingRect(convexhull2)\n",
        "    center_face2 = (int((x + x + w) / 2), int((y + y + h) / 2))\n",
        "\n",
        "    seamlessclone = cv2.seamlessClone(result, img2, img2_head_mask, center_face2, cv2.NORMAL_CLONE)\n",
        "\n",
        "    #cv2_imshow( seamlessclone)\n",
        "    cv2.waitKey(0)\n",
        "\n",
        "\n",
        "\n",
        "    cv2.destroyAllWindows()\n",
        "\n",
        "    return seamlessclone\n"
      ],
      "metadata": {
        "id": "pesAQtq1NuMz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img1 = cv2.imread(\"bradley_cooper.jpg\")\n",
        "img2 = cv2.imread(\"jim_carrey.jpg\")"
      ],
      "metadata": {
        "id": "mPvKnc4YPF5V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "real time face swapping - swap one face to a video"
      ],
      "metadata": {
        "id": "qHjvgaBMQ1Ej"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "\n",
        "# Load the input video\n",
        "input_video_path = '/content/Putin.mp4'\n",
        "cap = cv2.VideoCapture(input_video_path)\n",
        "\n",
        "# Get video properties\n",
        "fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
        "frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "\n",
        "# Create a VideoWriter object to write the output video\n",
        "output_video_path = '/content/real_time_video_faceswapped.mp4'\n",
        "fourcc = cv2.VideoWriter_fourcc(*'mp4v')  # Adjust the codec based on your needs\n",
        "out = cv2.VideoWriter(output_video_path, fourcc, fps, (frame_width, frame_height))\n",
        "\n",
        "# Loop through each frame in the input video\n",
        "while True:\n",
        "    ret, frame = cap.read()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    if not ret:\n",
        "        break  # Break the loop if no more frames are available\n",
        "\n",
        "    # Perform face swap (replace this line with your face swap function)\n",
        "    swapped_frame = faceswap(img1, frame)\n",
        "\n",
        "    # Write the swapped frame to the output video\n",
        "    out.write(swapped_frame)\n",
        "\n",
        "    # Display the swapped frame (optional)\n",
        "    cv2_imshow( swapped_frame)\n",
        "\n",
        "    # Break the loop if 'q' key is pressed\n",
        "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
        "        break\n",
        "\n",
        "# Release video capture and writer objects\n",
        "cap.release()\n",
        "out.release()\n",
        "\n",
        "# Close OpenCV windows\n",
        "cv2.destroyAllWindows()\n"
      ],
      "metadata": {
        "id": "ZF86-QqtQ-1Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "swap faces between two videos (swap the face from the source video to the face on the target video)"
      ],
      "metadata": {
        "id": "l9MjNlEEZC8A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import os\n",
        "\n",
        "\n",
        "# Open the video files\n",
        "video1_path = 'Trump.mp4'\n",
        "video2_path = 'Putin.mp4'\n",
        "cap1 = cv2.VideoCapture(video1_path)\n",
        "cap2 = cv2.VideoCapture(video2_path)\n",
        "\n",
        "# Check if the video files are opened successfully\n",
        "if not (cap1.isOpened() and cap2.isOpened()):\n",
        "    print(\"Error: Could not open one or more video files.\")\n",
        "    exit()\n",
        "\n",
        "# Get video properties\n",
        "fps = min(cap1.get(cv2.CAP_PROP_FPS), cap2.get(cv2.CAP_PROP_FPS))\n",
        "frame_width = int(min(cap1.get(cv2.CAP_PROP_FRAME_WIDTH), cap2.get(cv2.CAP_PROP_FRAME_WIDTH)))\n",
        "frame_height = int(min(cap1.get(cv2.CAP_PROP_FRAME_HEIGHT), cap2.get(cv2.CAP_PROP_FRAME_HEIGHT)))\n",
        "\n",
        "# Determine the minimum number of frames in the two videos\n",
        "min_frames = min(int(cap1.get(cv2.CAP_PROP_FRAME_COUNT)), int(cap2.get(cv2.CAP_PROP_FRAME_COUNT)))\n",
        "\n",
        "# Create an output directory to save frames\n",
        "output_directory = 'output_frames'\n",
        "os.makedirs(output_directory, exist_ok=True)\n",
        "\n",
        "# Create a VideoWriter object to save the output video\n",
        "output_video_path = '/content/video_to_video_faceswapped.mp4'\n",
        "fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
        "out = cv2.VideoWriter(output_video_path, fourcc, fps, (frame_width, frame_height))\n",
        "\n",
        "# Loop through each frame\n",
        "for frame_num in range(min_frames):\n",
        "    ret1, frame1 = cap1.read()\n",
        "    ret2, frame2 = cap2.read()\n",
        "\n",
        "    if not (ret1 and ret2):\n",
        "        break  # Break the loop if there are no more frames in one of the videos\n",
        "\n",
        "    try:\n",
        "    # Apply face swapping algorithm\n",
        "      swapped_frame = faceswap(frame1, frame2)\n",
        "\n",
        "    # Save the swapped frame\n",
        "      out.write(swapped_frame)\n",
        "\n",
        "      cv2_imshow(swapped_frame)\n",
        "    except:\n",
        "      print(\"cannot do the face swapping\")\n",
        "      out.write(frame2)\n",
        "      continue\n",
        "\n",
        "# Release video capture and writer objects\n",
        "cap1.release()\n",
        "cap2.release()\n",
        "out.release()\n",
        "\n",
        "print(f\"Face-swapped video saved at: {output_video_path}\")\n"
      ],
      "metadata": {
        "id": "Ru6v2UzObeKH"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}